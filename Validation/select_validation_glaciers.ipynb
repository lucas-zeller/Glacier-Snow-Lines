{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facbd4da",
   "metadata": {},
   "source": [
    "We are going to do a stratified random sampling to select glaciers to use for validation\n",
    "\n",
    "The stratified random sampling will work like this:\n",
    "1- All benchmark glaciers, glacier with in situ glaciological observations will be used: Wolverine, Gulkana, Lemon Creek, Taku, Eklutna\n",
    "2- A further series of 40 glaciers will be randomly chosen, with an equal number from each of the 4 major RGI subregions (regions 2,4,5,6)\n",
    "3- additionally, glaciers from each region will be chosen in a manner to ensure a distribution of glacier sizes. out of the 10 from each region, 5 will be 2-10km2, 3 will be 10-40km2, and 2 will be 40+ km2\n",
    "\n",
    "For each glacier, all available imagery (July to November) will be downloaded for all years (2000-2023), and we will determine the image which best captures the end of summer snow line (if such an image exists).\n",
    "Then, using that best image, multiple users will draw the 'idealized' snow line.\n",
    "This process will be repeated for both Landsat and Sentinel-2 imagery, with separate 'best' products chosen for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"01_rgi60_Alaska\", \"01_rgi60_Alaska.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c72c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\anaconda3\\envs\\AGVA_env\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "### select the benchmark glaciers which will be used\n",
    "benchmark_glacier_names = [\"Wolverine Glacier\", \"Gulkana Glacier\", \"Lemon Creek Glacier\", \"Taku Glacier\", \"Eklutna Glacier\"]\n",
    "benchmark_glacier_df = rgi_gdf[rgi_gdf['Name'].isin(benchmark_glacier_names)]\n",
    "\n",
    "# add a flag indicating the benchmark glaciers\n",
    "benchmark_glacier_df['Benchmark'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f305af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the other regions, select ten glaciers that will be used\n",
    "# define size ranges to split upon, numbers of each\n",
    "sizes = [2,10,40,99999]\n",
    "numbers = [5,3,2]\n",
    "\n",
    "validation_list = [benchmark_glacier_df]\n",
    "for r in [2,4,5,6]:\n",
    "    \n",
    "    # subset to this region\n",
    "    rgis_region = rgi_gdf[rgi_gdf['O2Region']==f'{r}']\n",
    "\n",
    "    # don't include benchmark glaciers\n",
    "    rgis_region = rgis_region[~rgis_region['Name'].isin(benchmark_glacier_names)]\n",
    "    \n",
    "    # for each size range, subset to those sizes and select a certain number\n",
    "    for i in (0,1,2):\n",
    "        \n",
    "        # subset sizes\n",
    "        rgis_subset = rgis_region[ (rgis_region['Area']>=sizes[i]) & (rgis_region['Area']<sizes[i+1]) ]\n",
    "        \n",
    "        # randomly select\n",
    "        randomly_sampled = rgis_subset.sample(n=numbers[i], replace=False, random_state=r)\n",
    "        \n",
    "        # append to list\n",
    "        validation_list.append(randomly_sampled)\n",
    "\n",
    "# make into single gdf\n",
    "rgi_all_validation = gpd.GeoDataFrame( pd.concat( validation_list, ignore_index=True) ).sort_values(['O2Region', 'Area']).reset_index()\n",
    "rgi_all_validation['Benchmark'] = np.nan_to_num(rgi_all_validation['Benchmark'], nan=0) \n",
    "\n",
    "# save to file\n",
    "out_path = os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv')\n",
    "out_df = rgi_all_validation[[\"O2Region\", \"RGIId\", \"Area\", \"Name\", \"Benchmark\"]].copy()\n",
    "# out_df.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502d8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save separate csv to hold the manually identified dates of best imagery\n",
    "# out_path = os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers - Best Dates.csv')\n",
    "# out_df = rgi_all_validation[[\"O2Region\", \"RGIId\", \"Area\", \"Name\", \"Benchmark\"]].copy().sort_values('Benchmark',ascending=False)\n",
    "# for y in range(2018,2023):\n",
    "#     out_df[f\"{y}_S2\"] = [0 for i in range(len(out_df))]\n",
    "# for y in range(2000,2023):\n",
    "#     out_df[f\"{y}_LS\"] = [0 for i in range(len(out_df))]\n",
    "# # out_df.to_csv(out_path, index=False)\n",
    "# out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2deaed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save separate csvs (one for each glacier) to hold the manually identified dates of best imagery\n",
    "out_path = os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers - Best Dates.csv')\n",
    "out_df = rgi_all_validation[[\"O2Region\", \"RGIId\", \"Area\", \"Name\", \"Benchmark\"]].copy().sort_values('Benchmark',ascending=False)\n",
    "\n",
    "years_all = ['2018_S2','2019_S2','2020_S2','2021_S2','2022_S2'] + [f\"{i}_LS\" for i in range(2000,2023)]\n",
    "zeros = [0 for i in years_all]\n",
    "\n",
    "for idx, row in out_df.iterrows():\n",
    "    # format some info\n",
    "    rgi_i = row['RGIId']\n",
    "    O2_i = row['O2Region']\n",
    "    name_i = str(row['Name']).replace(f\"/\", \"_\").replace(\" \", \"_\").replace(\"nan\", \"noname\")\n",
    "    \n",
    "    # create df\n",
    "    out_df = pd.DataFrame({\"RGIId\":[rgi_i for i in years_all], 'Year':years_all, 'Best Image':zeros, 'Next Image':zeros, 'Previous Image':zeros, \"All Ablation\":zeros, \"No Good Imagery\":zeros})\n",
    "    \n",
    "    out_path = os.path.join(folder_AGVA, 'Validation', 'Best Images', f'{rgi_i}_{O2_i}_{name_i}.csv')\n",
    "#     out_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893179f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shapefile with only these glaciers\n",
    "out_path = os.path.join(folder_AGVA, 'Validation', 'rgi', \"validation_rgi.shp\")\n",
    "rgi_all_validation.to_file(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0b77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
