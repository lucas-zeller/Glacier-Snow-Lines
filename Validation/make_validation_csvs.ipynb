{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facbd4da",
   "metadata": {},
   "source": [
    "Explore some comparisons between manually-delineated end-of-summer snow lines and the results from our automated delineation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c612c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import geopandas as gpd\n",
    "import gc\n",
    "import shapely\n",
    "import xarray as xr\n",
    "from rasterio.mask import mask\n",
    "import importlib\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import snowFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_validationlines = os.path.join(folder_AGVA, 'Validation', 'Snowline Traces')\n",
    "folder_mask = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks')\n",
    "folder_best_images = os.path.join(folder_AGVA, 'Validation', 'Best Images')\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"rgi_2km_o3regions\", \"rgi_2km_o3regions.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi)\n",
    "\n",
    "# choose whether to use the 'temporary' products from validaiton subfolder or the 'master' copy\n",
    "validation_folder_specific = 1\n",
    "\n",
    "if validation_folder_specific: \n",
    "    annual_aa_folder = os.path.join(folder_AGVA, 'Derived Products', 'S2', 'validation', 'Annual AAs')\n",
    "    annual_ela_folder = os.path.join(folder_AGVA, 'Derived Products', 'S2', 'validation', 'Annual AAs', 'csv')\n",
    "else:\n",
    "    annual_aa_folder = os.path.join(folder_AGVA, 'Derived Products', 'S2', 'Annual AAs')\n",
    "    annual_ela_folder = os.path.join(folder_AGVA, 'Derived Products', 'S2', 'Annual AAs', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b57c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RGI60-01.00557_2_noname.csv',\n",
       " 'RGI60-01.00565_2_Spur_Glacier.csv',\n",
       " 'RGI60-01.00570_2_Gulkana_Glacier.csv',\n",
       " 'RGI60-01.00787_6_noname.csv',\n",
       " 'RGI60-01.01104_6_Lemon_Creek_Glacier.csv',\n",
       " 'RGI60-01.01270_6_noname.csv',\n",
       " 'RGI60-01.01390_6_Taku_Glacier.csv',\n",
       " 'RGI60-01.01666_4_noname.csv',\n",
       " 'RGI60-01.01743_4_Sherman_Glacier.csv',\n",
       " 'RGI60-01.02584_6_noname.csv',\n",
       " 'RGI60-01.03215_6_noname.csv',\n",
       " 'RGI60-01.03379_6_noname.csv',\n",
       " 'RGI60-01.03741_6_Great_Glacier.csv',\n",
       " 'RGI60-01.05007_6_noname.csv',\n",
       " 'RGI60-01.05078_6_noname.csv',\n",
       " 'RGI60-01.08989_4_Eklutna_Glacier.csv',\n",
       " 'RGI60-01.09162_4_Wolverine_Glacier.csv',\n",
       " 'RGI60-01.09216_4_noname.csv',\n",
       " 'RGI60-01.09624_4_noname.csv',\n",
       " 'RGI60-01.09656_4_Langdon_Glacier.csv',\n",
       " 'RGI60-01.09798_4_Bainbridge_Glacier.csv',\n",
       " 'RGI60-01.10255_4_noname.csv',\n",
       " 'RGI60-01.10910_4_noname.csv',\n",
       " 'RGI60-01.12165_2_noname.csv',\n",
       " 'RGI60-01.12186_2_noname.csv',\n",
       " 'RGI60-01.12548_2_noname.csv',\n",
       " 'RGI60-01.13462_5_noname.csv',\n",
       " 'RGI60-01.13483_5_noname.csv',\n",
       " 'RGI60-01.13930_5_noname.csv',\n",
       " 'RGI60-01.14493_5_noname.csv',\n",
       " 'RGI60-01.15135_5_noname.csv',\n",
       " 'RGI60-01.15253_2_noname.csv',\n",
       " 'RGI60-01.15516_2_noname.csv',\n",
       " 'RGI60-01.15731_2_West_Fork_Glacier.csv',\n",
       " 'RGI60-01.16166_5_noname.csv',\n",
       " 'RGI60-01.16558_5_Dusty_Glacier.csv',\n",
       " 'RGI60-01.16719_5_noname.csv',\n",
       " 'RGI60-01.17321_5_noname.csv',\n",
       " 'RGI60-01.17784_4_Lowell_Glacier.csv',\n",
       " 'RGI60-01.19542_2_noname.csv',\n",
       " 'RGI60-01.20841_6_Muir_Glacier.csv',\n",
       " 'RGI60-01.21721_2_Toklat1.csv',\n",
       " 'RGI60-01.23606_4_noname.csv',\n",
       " 'RGI60-01.23643_5_Moraine_Apron_Glacier.csv',\n",
       " 'RGI60-01.26731_6_noname.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "rgis_to_analyze = all_validation_df['RGIId'].values\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "# get list of files in best images folder\n",
    "best_images_files = os.listdir(folder_best_images)\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "best_images_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7fada",
   "metadata": {},
   "source": [
    "### Lets plots the manually-mapped snowlines for each year on top of the automated end-of-summer snow cover product from each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0309f59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 of 45 - RGI60-01.08989 29.395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_auto</th>\n",
       "      <th>ELA_auto</th>\n",
       "      <th>AAR_auto</th>\n",
       "      <th>off_glacier_auto</th>\n",
       "      <th>date_manual</th>\n",
       "      <th>ELA_manual</th>\n",
       "      <th>AAR_manual</th>\n",
       "      <th>off_glacier_manual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>1523</td>\n",
       "      <td>0.2921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>0.2202</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>1508</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>1501</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>1543</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>1477</td>\n",
       "      <td>0.3894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_auto  ELA_auto  AAR_auto  off_glacier_auto date_manual  \\\n",
       "Year                                                                 \n",
       "2018  2018-09-15    1440.0    0.2294                 0  2018-09-14   \n",
       "2019  2019-09-02    1920.0    0.2202                 0  2019-08-30   \n",
       "2020  2020-08-27    1740.0    0.2845                 0  2020-08-27   \n",
       "2021  2021-09-11    1650.0    0.1456                 0  2021-09-11   \n",
       "2022  2022-09-14    1430.0    0.5168                 0  2022-08-10   \n",
       "\n",
       "      ELA_manual  AAR_manual  off_glacier_manual  \n",
       "Year                                              \n",
       "2018        1523      0.2921                   0  \n",
       "2019        1508      0.3268                   0  \n",
       "2020        1501      0.3412                   0  \n",
       "2021        1543      0.2510                   0  \n",
       "2022        1477      0.3894                   0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(rgis_to_analyze)):\n",
    "#     if i>0: continue\n",
    "\n",
    "    # get rgiid\n",
    "    rgi_i = rgis_to_analyze[i]\n",
    "    if rgi_i!='RGI60-01.08989': continue\n",
    "        \n",
    "    # grab the rgi outline that these lines correspond to\n",
    "    rgi_i_gdf = rgi_gdf[rgi_gdf['RGIId']==rgi_i].to_crs(\"EPSG:3338\")\n",
    "    ga = rgi_i_gdf['Area'].values[0]\n",
    "    \n",
    "    print(f\"{i+1} of {len(rgis_to_analyze)} - {rgi_i} {ga}\")\n",
    "    \n",
    "    # open glacier mask\n",
    "    glacier_mask = xr.open_dataset(os.path.join(folder_mask, f\"S2_{rgi_i}_mask.nc\"), chunks='auto').glacier\n",
    "    if ga>500:\n",
    "        glacier_mask = glacier_mask.coarsen({\"x\":3, \"y\":3}, boundary=\"trim\").median(skipna=True).astype('uint8') \n",
    "    glacier_pixels = np.nansum(glacier_mask)\n",
    "\n",
    "    # set file name/path\n",
    "    name = f'{rgi_i[:5]}_{rgi_i[6:8]}_{rgi_i[9:]}.geojson'\n",
    "    line_path = os.path.join(folder_validationlines, name)\n",
    "\n",
    "    # decide which columns you want to drop\n",
    "    bad_cols = ['id', 'SLCFlag', 'cloudShadowFlag', 'notes', 'otherImageFlag', 'partialPickFlag']\n",
    "    snowlines_gdf = gpd.read_file(line_path).drop(bad_cols, axis=1).to_crs(\"EPSG:3338\")\n",
    "\n",
    "    # add year as column\n",
    "    snowlines_gdf['Year'] = [int(i[:4]) for i in snowlines_gdf['Date']]\n",
    "    snowlines_gdf['y2'] = [int(i[:4]) for i in snowlines_gdf['Date']]\n",
    "\n",
    "    # in some instances there will be multiple entries for a single date (when the user went back to edit a previous image's snowline)\n",
    "    # in this case, we only want to keep the entry that has the full record (so the one with the latest index)\n",
    "    snowlines_gdf = snowlines_gdf[~snowlines_gdf.duplicated(subset='Date', keep='last')]\n",
    "\n",
    "    # clip to rgi outline (buffer inwards 10m to ensure we don't hit the edges)\n",
    "    snowlines_gdf = snowlines_gdf.clip(rgi_i_gdf.buffer(-10))\n",
    "    snowlines_gdf.set_index('Year', inplace=True)\n",
    "        \n",
    "    # open best images file\n",
    "    fname = [f for f in best_images_files if f.startswith(rgi_i)][0]\n",
    "    best_images_df = pd.read_csv(os.path.join(folder_best_images, fname))[:5]\n",
    "    best_images_df['Year'] = [int(d[:4]) for d in best_images_df['Year'] ]\n",
    "    best_images_df.set_index('Year', inplace=True)\n",
    "\n",
    "    # open files\n",
    "    annual_ela_path = os.path.join(annual_ela_folder, f\"S2_{rgi_i}_2018_2022_annual_AAs.csv\")\n",
    "    annual_ela_df = pd.read_csv(annual_ela_path)\n",
    "    annual_ela_df['Year'] = [int(i[:4]) for i in annual_ela_df['date']]\n",
    "    annual_ela_df.set_index('Year', inplace=True)\n",
    "    annual_ela_df = annual_ela_df.replace({'False':'0', 'True':'1'})\n",
    "\n",
    "    # create df to save all the info\n",
    "    save_df = pd.DataFrame({'Year':np.arange(2018,2023)})\n",
    "    save_df.set_index('Year', inplace=True)\n",
    "    \n",
    "    # add colummns from automated dataset\n",
    "    save_df['date_auto'] = annual_ela_df['date']\n",
    "    save_df['ELA_auto'] = annual_ela_df['ela']\n",
    "    save_df['AAR_auto'] = annual_ela_df['aar'].round(4)\n",
    "    save_df['off_glacier_auto'] = annual_ela_df['off_glacier'].astype(int)\n",
    "    \n",
    "    elas_manual = []\n",
    "    aars_manual = []\n",
    "\n",
    "    # get manual ela for each year\n",
    "    for i in range(5):\n",
    "        y=i+2018\n",
    "\n",
    "        # open the time-varying dem for this year\n",
    "        xr_dem = snowFun.get_year_DEM(rgi_i_gdf.geometry, y, smoothed=0)        \n",
    "        if ga>500:\n",
    "            xr_dem = xr_dem.sel({\"x\":glacier_mask.x, \"y\":glacier_mask.y})\n",
    "        xr_dem = xr.where(xr_dem<=0, np.nan, xr_dem)[0]\n",
    "         \n",
    "        # grab the manual validation product for this year\n",
    "        snowline_y = snowlines_gdf[snowlines_gdf['y2']==y]\n",
    "\n",
    "        # get manual snowline info if it's there\n",
    "        if len(snowline_y)>0:\n",
    "            # sample dem at 20m increments along each snowline\n",
    "            all_zs = snowFun.sample_dem_along_line(snowline_y, xr_dem, increment=20)\n",
    "\n",
    "            # get 50 percentile of elevation points\n",
    "            ela_manual_y = int(np.nanpercentile(all_zs, 50))\n",
    "            \n",
    "            # calculate the AAR based on this ELA\n",
    "            aar_manual_y = round(np.nansum(xr.where(xr_dem>=ela_manual_y, 1, 0))/glacier_pixels, 4)\n",
    "        \n",
    "        else:\n",
    "            ela_manual_y = -9999\n",
    "            aar_manual_y = -9999\n",
    "\n",
    "        # add elas to list\n",
    "        elas_manual.append(ela_manual_y)\n",
    "        aars_manual.append(aar_manual_y)\n",
    "\n",
    "    # add columns for manual dataset\n",
    "    save_df['date_manual'] = snowlines_gdf['Date']\n",
    "    save_df['ELA_manual'] = elas_manual\n",
    "    save_df['AAR_manual'] = aars_manual\n",
    "    save_df['off_glacier_manual'] = best_images_df['All Ablation']\n",
    "    \n",
    "    # save figure\n",
    "    out_path = os.path.join(folder_AGVA, 'Validation', 'comparison', f'{rgi_i}.csv')\n",
    "    save_df.to_csv(out_path)\n",
    "    \n",
    "save_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e6b10e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2018    False\n",
       "2019     True\n",
       "2020    -9999\n",
       "2021    -9999\n",
       "2022    False\n",
       "Name: off_glacier, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_ela_df['off_glacier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44803fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make another figure comparing manual and automated ela\n",
    "error_bars = [[i[0] for i in elas_manual], [i[2] for i in elas_manual]]\n",
    "xs = [i[1] for i in elas_manual]\n",
    "ys = elas_auto\n",
    "\n",
    "# initiate figure\n",
    "fig,axs = plt.subplots(figsize=(5,5),)\n",
    "\n",
    "# plot 1-1 line\n",
    "plt.plot([min(min(xs),min(ys)),max(max(xs),max(ys))],[min(min(xs),min(ys)),max(max(xs),max(ys))],\n",
    "        c='black', linestyle='dashed')\n",
    "\n",
    "# plot error bars\n",
    "axs.hlines(ys, xmin=error_bars[0], xmax=error_bars[1], color='grey', linewidth=1 )\n",
    "\n",
    "# plot points\n",
    "axs.scatter(xs, ys, zorder=5)\n",
    "\n",
    "# edits\n",
    "axs.set_xlabel('Manual ELA')\n",
    "axs.set_ylabel('Automated ELA')\n",
    "plt.tight_layout()\n",
    "axs.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr_dem = snowFun.get_year_DEM(rgi_i_gdf.geometry, 2019)\n",
    "# xr_dem = xr.where(xr_dem<=0, np.nan, xr_dem)[0]\n",
    "# xr_dem.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make figure\n",
    "# fig, axs = plt.subplots()\n",
    "# axs.set_facecolor('gainsboro')\n",
    "# rgi_i_gdf.plot(ax=axs, color='white')\n",
    "# rgi_i_gdf.boundary.plot(ax=axs, edgecolor='black', linewidth=1)\n",
    "# snowlines_gdf_clip.plot(ax=axs, column='Year', cmap=\"RdPu\", vmin=2017, vmax=2022, legend=True)\n",
    "# plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
