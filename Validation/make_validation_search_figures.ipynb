{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facbd4da",
   "metadata": {},
   "source": [
    "Create bulk figures to search for the best cloud-free image in each year for our validation glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "import gc\n",
    "from rasterio.mask import mask\n",
    "\n",
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_images = os.path.join('C:',os.sep,'Users','lzell','Documents','Validation Imagery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c72c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting each image for display. they will initially come in as [ (B,G,R,N), :, : ]\n",
    "band_r = 3\n",
    "band_g = 2\n",
    "band_b = 1\n",
    "\n",
    "def format_LS(array):\n",
    "    array = np.dstack( [array[band_r], array[band_g], array[band_b]] )\n",
    "    return np.clip((array / 45000), 0, 1)\n",
    "\n",
    "def format_S2(array):\n",
    "    array = np.dstack( [array[band_r], array[band_g], array[band_b]] )\n",
    "    return np.clip((array / 10000), 0, 1)\n",
    "\n",
    "# define folder paths\n",
    "S2_folder = os.path.join(folder_images, 'S2_all_validation_images')\n",
    "L9_folder = os.path.join(folder_images, 'L9_all_validation_images')\n",
    "L8_folder = os.path.join(folder_images, 'L8_all_validation_images')\n",
    "L7_folder = os.path.join(folder_images, 'L7_all_validation_images')\n",
    "L5_folder = os.path.join(folder_images, 'L5_all_validation_images')\n",
    "output_folder = os.path.join(folder_AGVA, 'Validation', 'all_validation_search')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52339d78",
   "metadata": {},
   "source": [
    "### Sentinel imagery here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f305af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGI60_01.00570_GS2A_20180706T211511_015870_N02.tif\n",
      "['RGI60_01.01390', 'RGI60_01.01104', 'RGI60_01.09162', 'RGI60_01.00570', 'RGI60_01.08989']\n",
      "4 RGI60_01.08989 2018, 43 rows, 2 cols, 84 images\n",
      "4 RGI60_01.08989 2019, 45 rows, 2 cols, 88 images\n",
      "4 RGI60_01.08989 2020, 44 rows, 2 cols, 87 images\n",
      "4 RGI60_01.08989 2021, 44 rows, 2 cols, 87 images\n",
      "4 RGI60_01.08989 2022, 43 rows, 2 cols, 85 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### go through and make S2 imagery into figures\n",
    "\n",
    "# get list of all S2 images we have (for all rgis)\n",
    "all_S2_images = os.listdir(S2_folder)\n",
    "print(all_S2_images[0])\n",
    "\n",
    "# get list of unique rgis\n",
    "all_S2_rgis = list(set( [i[:14] for i in all_S2_images] ))\n",
    "print(all_S2_rgis)\n",
    "\n",
    "# now for each unique rgi, go through to make images of it\n",
    "for i in range(len(all_S2_rgis)):\n",
    "    \n",
    "    rgi_i = all_S2_rgis[i]\n",
    "\n",
    "    # skip taku for now\n",
    "    if rgi_i != \"RGI60_01.08989\": continue  # 'RGI60_01.01104', 'RGI60_01.08989', 'RGI60_01.00570', 'RGI60_01.09162', 'RGI60_01.01390'\n",
    "#     if rgi_i == 'RGI60_01.01390': continue\n",
    "\n",
    "    # get list of the images we have for this rgi\n",
    "    rgi_image_names = [i for i in all_S2_images if i[:14]==rgi_i]\n",
    "    \n",
    "    # get date from all of these\n",
    "    rgi_image_dates = [i[20:28] for i in rgi_image_names]\n",
    "    rgi_image_dates = [f\"{str(i)[:4]}-{str(i)[4:6]}-{str(i)[6:8]}\" for i in rgi_image_dates]\n",
    "\n",
    "    # get year from each\n",
    "    rgi_image_years = [int(i[:4]) for i in rgi_image_dates]\n",
    "    \n",
    "    # make into df\n",
    "    rgi_df = pd.DataFrame({'year':rgi_image_years, 'date':rgi_image_dates, 'path':rgi_image_names})\n",
    "    rgi_df = rgi_df.sort_values('date')\n",
    "    \n",
    "    # for each year, make different images\n",
    "    save=1\n",
    "    for y in [2018,2019,2020,2021,2022]:\n",
    "#         if y>2018: continue\n",
    "\n",
    "        rgi_df_subset = rgi_df[rgi_df['year']==y]\n",
    "        if len(rgi_df_subset)<1: continue\n",
    "\n",
    "        rgi_df_subset = rgi_df_subset.sort_values('date')\n",
    "\n",
    "        # start the image. have 4x4 inch square for each image\n",
    "        # 2 columns, as many rows as needed\n",
    "        ncol = 2\n",
    "        nrow = max( len(rgi_df_subset)//ncol + 1, 2 )\n",
    "        width = 8\n",
    "        height = nrow*4\n",
    "        \n",
    "        if height>160: # figures cant be more than 160 inches tall, so we have to set dpi to smaller in this case\n",
    "            dpi = int(65000/height)\n",
    "        else:\n",
    "            dpi=400\n",
    "        \n",
    "        print(f\"{i} {rgi_i} {y}, {nrow} rows, {ncol} cols, {len(rgi_df_subset)} images\")\n",
    "        fig, axs = plt.subplots(nrow, ncol, figsize=(width,height), dpi=dpi)\n",
    "\n",
    "        # iterate through subset df, opening each image and placing it on the output ifgure\n",
    "        c=0\n",
    "        for idx, row in rgi_df_subset.iterrows():\n",
    "            # if c>5: continue \n",
    "\n",
    "            ax = axs[c//ncol, c%ncol]\n",
    "            c+=1\n",
    "\n",
    "            # define image path, open it\n",
    "            image_filepath = os.path.join(S2_folder, row['path'])\n",
    "            image = rio.open(image_filepath).read()\n",
    "            # print(image.shape)\n",
    "\n",
    "            # format for display\n",
    "            image = format_S2(image)\n",
    "            # print(image_display.shape)\n",
    "\n",
    "            # add to figure\n",
    "            ax.imshow(image, interpolation='nearest')\n",
    "\n",
    "            # add date to figure\n",
    "            ax.set_title(row['date'], size=6, pad=0)\n",
    "        \n",
    "        # final edits\n",
    "        for ax in axs:\n",
    "            for a in ax:\n",
    "                a.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # save as png\n",
    "        if save:\n",
    "            save_path = os.path.join(output_folder, f\"{rgi_i}_S2_{y}.png\")\n",
    "            fig.savefig(save_path, dpi=dpi, bbox_inches='tight', pad_inches=0.05, transparent=False)\n",
    "        \n",
    "        # close figure, clear variables\n",
    "        plt.close()\n",
    "        del image\n",
    "        # del image_display\n",
    "        del fig, axs, ax, a\n",
    "        del row, rgi_df_subset, idx\n",
    "        gc.collect()\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e472bb",
   "metadata": {},
   "source": [
    "### Landsat imagery here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec51cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### go through and make landsat imagery into figures\n",
    "\n",
    "# get list of all landsat images we have (for all rgis)\n",
    "all_L5_images = os.listdir(L5_folder)\n",
    "all_L7_images = os.listdir(L7_folder)\n",
    "all_L8_images = os.listdir(L8_folder)\n",
    "all_L9_images = os.listdir(L9_folder)\n",
    "all_LS_images = all_L5_images + all_L7_images + all_L8_images + all_L9_images\n",
    "print(all_LS_images[0])\n",
    "\n",
    "# get list of unique rgis\n",
    "all_LS_rgis = list(set( [i[:14] for i in all_LS_images] ))\n",
    "print(all_LS_rgis)\n",
    "\n",
    "# now for each unique rgi, go through to make images of it\n",
    "for i in range(len(all_LS_rgis)):\n",
    "    # if i>0: continue\n",
    "    # print(i)\n",
    "\n",
    "    rgi_i = all_LS_rgis[i]\n",
    "\n",
    "    # skip taku for now\n",
    "    if rgi_i != \"RGI60_01.08989\": continue # 'RGI60_01.09162', 'RGI60_01.01104', 'RGI60_01.00570', 'RGI60_01.08989', 'RGI60_01.01390'\n",
    "    # if rgi_i == 'RGI60_01.01390': continue\n",
    "\n",
    "    # get list of the images we have for this rgi\n",
    "    rgi_image_names = [i for i in all_LS_images if i[:14]==rgi_i]\n",
    "\n",
    "    # get date from all of these\n",
    "    rgi_image_dates = [i[32:40] for i in rgi_image_names]\n",
    "    rgi_image_dates = [f\"{str(i)[:4]}-{str(i)[4:6]}-{str(i)[6:8]}\" for i in rgi_image_dates]\n",
    "    # print(rgi_image_dates[0])\n",
    "\n",
    "    # get year from each\n",
    "    rgi_image_years = [int(i[:4]) for i in rgi_image_dates]\n",
    "\n",
    "    # get satellite from each\n",
    "    rgi_sats = [i[18] for i in rgi_image_names]\n",
    "\n",
    "    # make into df\n",
    "    rgi_df = pd.DataFrame({'year':rgi_image_years, 'date':rgi_image_dates, 'path':rgi_image_names, 'sat':rgi_sats})\n",
    "    rgi_df = rgi_df.sort_values('date')\n",
    "    # print(rgi_df.head())\n",
    "\n",
    "    # for each year, make different images\n",
    "    save=1\n",
    "    for y in range(2000,2023):\n",
    "\n",
    "        # if y>2017: continue\n",
    "        # if y>2018: continue\n",
    "\n",
    "        rgi_df_subset = rgi_df[rgi_df['year']==y]\n",
    "        if len(rgi_df_subset)<1: continue\n",
    "\n",
    "        rgi_df_subset = rgi_df_subset.sort_values('date')\n",
    "\n",
    "        # start the image. have 4x4 inch square for each image\n",
    "        # 2 columns, as many rows as needed\n",
    "        ncol = 2\n",
    "        nrow = max( len(rgi_df_subset)//ncol + 1, 2 )\n",
    "        width = 8\n",
    "        height = nrow*4\n",
    "\n",
    "        print(f\"{i} {rgi_i} {y}, {nrow} rows, {ncol} cols, {len(rgi_df_subset)} images\")\n",
    "        fig, axs = plt.subplots(nrow, ncol, figsize=(width,height), dpi=400, num=1)\n",
    "\n",
    "        # iterate through subset df, opening each image and placing it on the output ifgure\n",
    "        c=0\n",
    "        for idx, row in rgi_df_subset.iterrows():\n",
    "            # if c>5: continue\n",
    "\n",
    "            ax = axs[c//ncol, c%ncol]\n",
    "            c+=1\n",
    "\n",
    "            # define image path, open it\n",
    "            if row['sat']=='5': ls_folder = L5_folder\n",
    "            if row['sat']=='7': ls_folder = L7_folder\n",
    "            if row['sat']=='8': ls_folder = L8_folder\n",
    "\n",
    "            image_filepath = os.path.join(ls_folder, row['path'])\n",
    "            image = rio.open(image_filepath).read()\n",
    "            # print(image.shape)\n",
    "\n",
    "            # format for display\n",
    "            image = format_LS(image)\n",
    "            # print(image_display.shape)\n",
    "\n",
    "            # add to figure\n",
    "            ax.imshow(image, interpolation='nearest')\n",
    "\n",
    "            # add date to figure\n",
    "            ax.set_title(row['date'], size=6, pad=0)\n",
    "\n",
    "        # final edits\n",
    "        for ax in axs:\n",
    "            for a in ax:\n",
    "                a.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # save as png\n",
    "        if save:\n",
    "            save_path = os.path.join(output_folder, f\"{rgi_i}_LS_{y}.png\")\n",
    "            fig.savefig(save_path, dpi=400, bbox_inches='tight', pad_inches=0.05, transparent=False)\n",
    "\n",
    "        # close figure, clear variables\n",
    "        plt.close()\n",
    "        del image\n",
    "        # del image_display\n",
    "        del fig, axs, ax, a\n",
    "        del row, rgi_df_subset, idx\n",
    "        gc.collect()\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
