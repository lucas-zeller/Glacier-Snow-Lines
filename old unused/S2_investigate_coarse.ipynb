{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import snowFun\n",
    "import dask.array\n",
    "# %matplotlib widget\n",
    "\n",
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_dems = os.path.join(folder_AGVA, \"DEMs\", \"time_varying_DEMs\", \"10m\")\n",
    "folder_class = os.path.join(folder_AGVA, 'classified images', 'S2_Classified_Cloudmasked_Merged')\n",
    "folder_cloud = os.path.join(folder_AGVA, 'classified images', 'S2_Cloud_Merged')\n",
    "folder_meta = os.path.join(folder_AGVA, \"classified images\", \"meta csv\", \"S2\")\n",
    "folder_mask = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks')\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"01_rgi60_Alaska\", \"01_rgi60_Alaska.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0c2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n",
      "               RGIId     Area\n",
      "829   RGI60-01.20889    [2.0]\n",
      "254   RGI60-01.11632    [2.0]\n",
      "153   RGI60-01.08203  [2.002]\n",
      "2486  RGI60-01.25183  [2.002]\n",
      "2851  RGI60-01.11595  [2.003]\n",
      "2207  RGI60-01.09047  [2.004]\n",
      "557   RGI60-01.03614  [2.004]\n",
      "40    RGI60-01.05487  [2.004]\n",
      "417   RGI60-01.03088  [2.005]\n",
      "1695  RGI60-01.10867  [2.005]\n"
     ]
    }
   ],
   "source": [
    "### choose if you want to do only the 45 validation glaciers\n",
    "validation_only = 0\n",
    "\n",
    "# load rgi names that have been saved to the classified folder\n",
    "rgis_folder = list(set( [ i[3:17] for i in os.listdir(folder_class) if i!='merged.vrt' ] ))\n",
    "\n",
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "\n",
    "# get rgi names for given o2 region\n",
    "rgis_o2 = rgi_gdf[rgi_gdf['O2Region']=='4']['RGIId'].values\n",
    "\n",
    "# select which rgis to analyze\n",
    "if validation_only:\n",
    "    rgis_to_analyze = list( set(rgis_folder).intersection(set(all_validation_df['RGIId'].values)) )\n",
    "else:\n",
    "    # rgis_to_analyze = [\"RGI60-01.09162\"] # just a single rgi\n",
    "    rgis_to_analyze = rgis_folder # everything that is available\n",
    "#     rgis_to_analyze = list( set(rgis_folder).intersection(set(rgis_o2)) ) # all the rgis in the folder than are in this o2region\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "# print(rgis_to_analyze[:10])\n",
    "print(rgis_to_analyze_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0d78c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3031 of 3031: RGI60-01.17423  512.357 km2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# subset rgi to single outline, by choosing rgiid or rgi name\n",
    "rgiid = \"RGI60-01.17423\"\n",
    "\n",
    "# quickly grab glacier area\n",
    "ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area'].values[0]\n",
    "\n",
    "# choose how much to coarsen (more coarse for bigger glaciers) \n",
    "if ga>1000:\n",
    "    scale=5\n",
    "else:\n",
    "    scale=3\n",
    "\n",
    "# set folder\n",
    "if validation_only:\n",
    "    folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Validation')\n",
    "else:\n",
    "    folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2')\n",
    "\n",
    "# get geometry\n",
    "rgi_single = rgi_gdf[rgi_gdf['RGIId']==rgiid].to_crs(\"EPSG:3338\")\n",
    "single_geometry = rgi_single.geometry\n",
    "\n",
    "# print progress\n",
    "print(f\"\\nStarting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga} km2\")\n",
    "\n",
    "# single_geometry = single_geometry.buffer(-100) #what if we buffer out the exterior 100 meters of the glacier\n",
    "\n",
    "# open glacier mask\n",
    "glacier_mask = xr.open_dataset(os.path.join(folder_mask, f\"S2_{rgiid}_mask.nc\"), chunks='auto').glacier\n",
    "\n",
    "# open dem\n",
    "xr_dem = snowFun.get_year_DEM(single_geometry, 2018, smoothed=0)\n",
    "\n",
    "# open data\n",
    "path_open = os.path.join(folder_save, 'Daily AAs', f\"S2_{rgiid}_{2018}_daily_AAs_coarse.nc\")\n",
    "snow = xr.open_dataset(path_open, chunks={'time':10})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4d0b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3704, 3767)\n",
      "(1, 3704, 3767)\n",
      "Frozen({'time': 122, 'y': 1234, 'x': 1255})\n"
     ]
    }
   ],
   "source": [
    "print(glacier_mask.shape)\n",
    "print(xr_dem.shape)\n",
    "print(snow.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d98bc457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1234, 1255)\n",
      "(1, 1234, 1255)\n"
     ]
    }
   ],
   "source": [
    "mask = glacier_mask.sel({\"x\":snow.x, \"y\":snow.y})\n",
    "dem = xr_dem.sel({\"x\":snow.x, \"y\":snow.y})\n",
    "print(mask.shape)\n",
    "print(dem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd06a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[647305. 647335. 647365. ... 684865. 684895. 684925.]\n",
      "[647305. 647335. 647365. ... 684865. 684895. 684925.]\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 5, y: 5, x: 5)\n",
      "Coordinates:\n",
      "  * x            (x) float64 6.473e+05 6.473e+05 6.474e+05 6.474e+05 6.474e+05\n",
      "  * y            (y) float64 1.331e+06 1.331e+06 1.331e+06 1.331e+06 1.331e+06\n",
      "    spatial_ref  int32 ...\n",
      "  * time         (time) datetime64[ns] 2018-05-01 2018-05-03 ... 2018-05-08\n",
      "Data variables:\n",
      "    class        (time, y, x) uint8 dask.array<chunksize=(5, 5, 5), meta=np.ndarray>\n",
      "<xarray.DataArray 'glacier' (y: 5, x: 5)>\n",
      "dask.array<getitem, shape=(5, 5), dtype=bool, chunksize=(5, 5), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * x            (x) float64 6.473e+05 6.473e+05 6.474e+05 6.474e+05 6.474e+05\n",
      "  * y            (y) float64 1.331e+06 1.331e+06 1.331e+06 1.331e+06 1.331e+06\n",
      "    spatial_ref  int32 ...\n",
      "Attributes:\n",
      "    res:          [10 10]\n",
      "    crs:          EPSG:3338\n",
      "    transform:    [ 10   0   0   0 -10   0]\n",
      "    long_name:    RGI60-01.17423\n",
      "    description:  0: off 1: on\n"
     ]
    }
   ],
   "source": [
    "print(test.x.values)\n",
    "print(snow.x.values)\n",
    "print(snow.head())\n",
    "print(test.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
