{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313fbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import dask.array\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import snowFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_dems = os.path.join(folder_AGVA, \"DEMs\", \"time_varying_DEMs\", \"10m\")\n",
    "folder_class = os.path.join(folder_AGVA, 'classified images', 'S2_Classified_Cloudmasked_Merged')\n",
    "folder_cloud = os.path.join(folder_AGVA, 'classified images', 'S2_Cloud_Merged')\n",
    "folder_meta = os.path.join(folder_AGVA, \"classified images\", \"meta csv\", \"S2\")\n",
    "folder_mask = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks')\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"rgi_2km_o3regions\", \"rgi_2km_o3regions.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0c2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n"
     ]
    }
   ],
   "source": [
    "### choose if you want to do only the 45 validation glaciers\n",
    "validation_only = 0\n",
    "\n",
    "# load rgi names that have been saved to the classified folder\n",
    "rgis_folder = list(set( [ i[3:17] for i in os.listdir(folder_class) if i!='merged.vrt' ] ))\n",
    "\n",
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "\n",
    "# get rgi names for given o2 region\n",
    "rgis_o2 = rgi_gdf[rgi_gdf['O2Region']=='4']['RGIId'].values\n",
    "\n",
    "# select which rgis to analyze\n",
    "if validation_only:\n",
    "    rgis_to_analyze = list( set(rgis_folder).intersection(set(all_validation_df['RGIId'].values)) )\n",
    "else:\n",
    "    # rgis_to_analyze = [\"RGI60-01.09162\"] # just a single rgi\n",
    "    rgis_to_analyze = rgis_folder # everything that is available\n",
    "#     rgis_to_analyze = list( set(rgis_folder).intersection(set(rgis_o2)) ) # all the rgis in the folder than are in this o2region\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "# print(rgis_to_analyze[:10])\n",
    "# print(rgis_to_analyze_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d78c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3010 of 3031: RGI60-01.17423  512.357 km2\n",
      "576980\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3011 of 3031: RGI60-01.13538  514.803 km2\n",
      "575781\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3012 of 3031: RGI60-01.01390  521.396 km2\n",
      "581909\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3013 of 3031: RGI60-01.03377  523.786 km2\n",
      "586922\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3014 of 3031: RGI60-01.27108  534.228 km2\n",
      "598455\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3015 of 3031: RGI60-01.20796  549.286 km2\n",
      "613208\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3016 of 3031: RGI60-01.16545  582.83 km2\n",
      "653233\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3017 of 3031: RGI60-01.16121  592.219 km2\n",
      "663176\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3018 of 3031: RGI60-01.04375  612.706 km2\n",
      "685123\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3019 of 3031: RGI60-01.26738  718.416 km2\n",
      "805904\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3020 of 3031: RGI60-01.14883  743.599 km2\n",
      "831494\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3021 of 3031: RGI60-01.10689  773.873 km2\n",
      "865957\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3022 of 3031: RGI60-01.23649  832.278 km2\n",
      "930036\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3023 of 3031: RGI60-01.17614  925.341 km2\n",
      "1039150\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3024 of 3031: RGI60-01.17183  958.616 km2\n",
      "1073501\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3025 of 3031: RGI60-01.14683  1019.101 km2\n",
      "410711\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3026 of 3031: RGI60-01.15769  1028.799 km2\n",
      "413204\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3027 of 3031: RGI60-01.16201  1053.721 km2\n",
      "424963\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3028 of 3031: RGI60-01.17566  1177.246 km2\n",
      "475208\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3029 of 3031: RGI60-01.14443  2834.493 km2\n",
      "1141926\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3030 of 3031: RGI60-01.13635  3025.115 km2\n",
      "1216460\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 3031 of 3031: RGI60-01.13696  3362.656 km2\n",
      "1351187\n",
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzell\\AppData\\Local\\Temp\\ipykernel_3084\\1508650737.py:69: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
      "C:\\Users\\lzell\\Anaconda3\\envs\\AGVA_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(rgis_to_analyze)):\n",
    "#     if c>0: continue\n",
    "    \n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]\n",
    "\n",
    "    # quickly grab glacier area\n",
    "    ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area'].values[0]\n",
    "    \n",
    "    # if ga<500, we are not going to do any coarsening\n",
    "    if ga<500:\n",
    "        continue\n",
    "\n",
    "    # choose how much to coarsen (more coarse for bigger glaciers) \n",
    "    if ga>1000:\n",
    "        scale=5\n",
    "    else:\n",
    "        scale=3\n",
    "    \n",
    "    # set folder\n",
    "    if validation_only:\n",
    "        folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Validation')\n",
    "    else:\n",
    "        folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2')\n",
    "       \n",
    "    # check if this glacier has been run already, skip if so\n",
    "    temp_path = os.path.join(folder_save, 'Daily AAs', f\"S2_{rgiid}_2022_daily_AAs_shadowed_coarse.nc\")\n",
    "#     if os.path.exists(temp_path):\n",
    "#         continue\n",
    "    \n",
    "    # print progress\n",
    "    print(f\"\\nStarting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga} km2\")\n",
    "#     continue\n",
    "    # grab just this rgi geometry and info\n",
    "    rgi_single = rgi_gdf[rgi_gdf['RGIId']==rgiid].to_crs(\"EPSG:3338\")\n",
    "    single_geometry = rgi_single.geometry\n",
    "\n",
    "    # single_geometry = single_geometry.buffer(-100) #what if we buffer out the exterior 100 meters of the glacier\n",
    " \n",
    "    # open glacier mask, count how many pixels there are\n",
    "    glacier_mask = xr.open_dataset(os.path.join(folder_mask, f\"S2_{rgiid}_mask.nc\"), chunks='auto').glacier\n",
    "    glacier_mask = glacier_mask.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True).astype('uint8')\n",
    "    glacier_pixels = glacier_mask.sum().values\n",
    "    print(glacier_pixels)\n",
    "    \n",
    "#     # open the observed faction df\n",
    "#     obs_path = os.path.join(folder_save, 'Daily AAs', 'observed', f\"S2_{rgiid}_observed.csv\")\n",
    "#     obs_df = pd.read_csv(obs_path)\n",
    "    \n",
    "    # for each year, open the daily data, coarsen and resave\n",
    "    for y in [2018,2019,2020,2021,2022]:\n",
    "        print(y)\n",
    "        \n",
    "        # open data\n",
    "        path_open = os.path.join(folder_save, 'Daily AAs', f\"S2_{rgiid}_{y}_daily_AAs_shadowed.nc\")\n",
    "        \n",
    "        # if small glacier, we dont need to chunk\n",
    "        if ga>500:\n",
    "            snow = xr.open_dataset(path_open, chunks={'time':1})\n",
    "        else:\n",
    "            snow = xr.open_dataset(path_open, chunks={'time':10})\n",
    "\n",
    "        # make 1=snow, 0=ablation, nan=cloud,shadow,off-glacier\n",
    "        snow = snow.where(snow!=0, np.nan).where(snow<=1, 0)\n",
    "#         print(snow.dims)\n",
    "        \n",
    "        # coarsen snow product\n",
    "        snow = snow.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True)\n",
    "#         print(snow.dims)\n",
    "\n",
    "        # fix to 0(nodata), 1(ablation), 2(snow)\n",
    "        snow = xr.where(snow.isnull(), 0, xr.where(snow>=0.5, 2, 1)).astype('uint8')\n",
    "        \n",
    "        # reapply mask\n",
    "        snow = snow.where(glacier_mask>0.5,0).astype('uint8')\n",
    "        \n",
    "        # save\n",
    "        path_temp = os.path.join(folder_save, 'Daily AAs', f\"S2_{rgiid}_{y}_daily_AAs_shadowed_coarse.nc\")\n",
    "        encoding = {\"class\":{\"zlib\": True, \"dtype\": \"uint8\"}}\n",
    "        snow.to_netcdf(path_temp, encoding=encoding)\n",
    "     \n",
    "     # then go through and calculate the percent useable on each date\n",
    "#     print(\"Calculating percents\")\n",
    "#     for y in [2018,2019,2020,2021,2022]:\n",
    "\n",
    "#         # open\n",
    "#         path = os.path.join(folder_save, 'Daily AAs', f\"S2_{rgiid}_{y}_daily_AAs_shadowed_coarse.nc\")\n",
    "#         snow = xr.open_dataset(path, chunks={'band':1, 'y':-1, 'x':-1}).to_array()\n",
    "        \n",
    "#         # get dates\n",
    "#         dates = snow.time.values\n",
    "#         dates = [str(d)[:10] for d in dates]\n",
    "        \n",
    "#         # count usable fraction each date\n",
    "#         percent_usable_by_time = (xr.where(snow>0, 1, 0).sum(dim=['x','y'])).compute().values[0]\n",
    "# #         print()\n",
    "        \n",
    "#         # scale correctly\n",
    "#         percent_usable_by_time = percent_usable_by_time/glacier_pixels #*scale*scale\n",
    "# #         print(len(percent_usable_by_time))\n",
    "        \n",
    "#         # add to obs_df\n",
    "#         obs_df.loc[obs_df['Date'].isin(dates), 'observed_initial'] = percent_usable_by_time.round(4)\n",
    "#         obs_df.to_csv(obs_path, index=False)\n",
    "        \n",
    "#     c+=1\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318adc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
