{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed27064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dask.array\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import snowFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_dems = os.path.join(folder_AGVA, \"DEMs\", \"time_varying_DEMs\", \"10m\")\n",
    "folder_class = os.path.join(folder_AGVA, 'classified images', 'S2_Classified_Cloudmasked_Merged')\n",
    "folder_cloud = os.path.join(folder_AGVA, 'classified images', 'S2_Cloud_Merged')\n",
    "folder_meta = os.path.join(folder_AGVA, \"classified images\", \"meta csv\", \"S2\")\n",
    "folder_mask = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks')\n",
    "folder_slope = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Slopes')\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"rgi_2km_o3regions\", \"rgi_2km_o3regions.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi, drop='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f735687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "### choose if you want to do only the 45 validation glaciers\n",
    "validation_only = 1\n",
    "\n",
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "\n",
    "### get list of all the glaciers for which we have calculated the snow covered fractions\n",
    "# select which rgis to analyze\n",
    "if validation_only:\n",
    "    folder_ela = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Validation', 'ELAs')\n",
    "    folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Validation')\n",
    "else:\n",
    "    folder_sca = os.path.join(folder_AGVA, 'Derived products', 'S2', 'ELAs')\n",
    "    folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2')\n",
    "\n",
    "# load rgi names that have been saved to the classified folder\n",
    "rgis_to_analyze = list(set( [ i[:14] for i in os.listdir(folder_ela) if i!='merged.vrt' ] ))\n",
    "# rgis_to_analyze.sort()\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "# print(rgis_to_analyze[:10])\n",
    "# print(rgis_to_analyze_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920b561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 1 of 45: RGI60-01.10910  2.084 km2\n",
      "\n",
      "Starting 2 of 45: RGI60-01.00787  2.126 km2\n",
      "\n",
      "Starting 3 of 45: RGI60-01.23606  2.344 km2\n",
      "\n",
      "Starting 4 of 45: RGI60-01.15253  2.551 km2\n",
      "\n",
      "Starting 5 of 45: RGI60-01.03379  2.578 km2\n",
      "\n",
      "Starting 6 of 45: RGI60-01.16719  2.681 km2\n",
      "\n",
      "Starting 7 of 45: RGI60-01.17321  2.88 km2\n",
      "\n",
      "Starting 8 of 45: RGI60-01.13462  3.206 km2\n",
      "\n",
      "Starting 9 of 45: RGI60-01.13483  3.216 km2\n",
      "\n",
      "Starting 10 of 45: RGI60-01.02584  3.441 km2\n",
      "\n",
      "Starting 11 of 45: RGI60-01.03215  3.998 km2\n",
      "\n",
      "Starting 12 of 45: RGI60-01.01666  4.243 km2\n",
      "\n",
      "Starting 13 of 45: RGI60-01.12548  4.314 km2\n",
      "\n",
      "Starting 14 of 45: RGI60-01.13930  4.404 km2\n",
      "\n",
      "Starting 15 of 45: RGI60-01.09624  4.487 km2\n",
      "\n",
      "Starting 16 of 45: RGI60-01.15516  4.764 km2\n",
      "\n",
      "Starting 17 of 45: RGI60-01.21721  6.422 km2\n",
      "\n",
      "Starting 18 of 45: RGI60-01.10255  7.262 km2\n",
      "\n",
      "Starting 19 of 45: RGI60-01.12165  7.969 km2\n",
      "\n",
      "Starting 20 of 45: RGI60-01.05007  9.216 km2\n",
      "\n",
      "Starting 21 of 45: RGI60-01.01104  9.528 km2\n",
      "\n",
      "Starting 22 of 45: RGI60-01.12186  11.05 km2\n",
      "\n",
      "Starting 23 of 45: RGI60-01.09656  13.791 km2\n",
      "\n",
      "Starting 24 of 45: RGI60-01.17784  14.773 km2\n",
      "\n",
      "Starting 25 of 45: RGI60-01.14493  15.336 km2\n",
      "\n",
      "Starting 26 of 45: RGI60-01.23643  15.732 km2\n",
      "\n",
      "Starting 27 of 45: RGI60-01.01270  16.163 km2\n",
      "\n",
      "Starting 28 of 45: RGI60-01.09162  16.749 km2\n",
      "\n",
      "Starting 29 of 45: RGI60-01.05078  17.259 km2\n",
      "\n",
      "Starting 30 of 45: RGI60-01.00570  17.567 km2\n",
      "\n",
      "Starting 31 of 45: RGI60-01.00557  18.042 km2\n",
      "\n",
      "Starting 32 of 45: RGI60-01.09216  18.634 km2\n",
      "\n",
      "Starting 33 of 45: RGI60-01.26731  20.207 km2\n",
      "\n",
      "Starting 34 of 45: RGI60-01.00565  23.06 km2\n",
      "\n",
      "Starting 35 of 45: RGI60-01.08989  29.395 km2\n",
      "\n",
      "Starting 36 of 45: RGI60-01.16166  29.932 km2\n",
      "\n",
      "Starting 37 of 45: RGI60-01.15731  40.009 km2\n",
      "\n",
      "Starting 38 of 45: RGI60-01.09798  41.785 km2\n",
      "\n",
      "Starting 39 of 45: RGI60-01.01743  45.165 km2\n",
      "\n",
      "Starting 40 of 45: RGI60-01.15135  66.067 km2\n",
      "\n",
      "Starting 41 of 45: RGI60-01.19542  71.722 km2\n",
      "\n",
      "Starting 42 of 45: RGI60-01.20841  80.284 km2\n",
      "\n",
      "Starting 43 of 45: RGI60-01.03741  136.264 km2\n",
      "\n",
      "Starting 44 of 45: RGI60-01.16558  343.098 km2\n",
      "\n",
      "Starting 45 of 45: RGI60-01.01390  521.396 km2\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "skip = 0\n",
    "for i in range(len(rgis_to_analyze)):\n",
    "\n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]\n",
    "#     if rgiid!='RGI60-01.15731': continue\n",
    "        \n",
    "    rgiid = rgis_to_analyze[i]\n",
    "    \n",
    "    # quickly grab glacier area\n",
    "    ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area'].values[0]\n",
    "\n",
    "#     if ga>300: continue\n",
    "    \n",
    "    # print progress\n",
    "    print(f\"\\nStarting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga} km2\")\n",
    "    \n",
    "    # open glacier mask\n",
    "    glacier_mask = xr.open_dataset(os.path.join(folder_mask, f\"S2_{rgiid}_mask.nc\"), chunks='auto').glacier\n",
    "        \n",
    "    # define the coarsen scale\n",
    "    if ga>1000:\n",
    "        scale=5\n",
    "    elif ga>500:\n",
    "        scale=3\n",
    "    else:\n",
    "        scale=1\n",
    "        \n",
    "    if ga>500:\n",
    "        glacier_mask = glacier_mask.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True).astype('uint8')\n",
    "        \n",
    "    # open glacier slope\n",
    "    glacier_slope = xr.open_dataset(os.path.join(folder_slope, f\"S2_{rgiid}_slope.nc\"), chunks='auto').slope\n",
    "    max_slope = 25   \n",
    "    \n",
    "    # create binary mask for what is usable slopes\n",
    "    slope_mask = xr.where(glacier_slope<=max_slope, 1, 0)\n",
    "    \n",
    "    # make sure dimensions match up\n",
    "    slope_mask = slope_mask.reindex_like(glacier_mask, method='nearest')\n",
    "    \n",
    "    # coarsen if big glacier\n",
    "#     glacier_slope = glacier_slope.sel({\"x\":glacier_mask.x, \"y\":glacier_mask.y})\n",
    "    \n",
    "    # function to format metadata and attributes\n",
    "    def format_xr_to_save(xr_da):\n",
    "        xr_da.attrs[\"res\"] = (10*scale,10*scale)\n",
    "        xr_da.attrs[\"crs\"] = \"EPSG:3338\"\n",
    "        xr_da.attrs[\"transform\"] = [10,0,0,0,-10,0]\n",
    "        xr_da.attrs[\"_FillValue\"] = 0\n",
    "        xr_da.attrs[\"long_name\"] = rgiid\n",
    "        xr_da.attrs[\"description\"] = \"0: off glacier, no data. 1: ablation. 2: accumulation. 3: on glacier, no data\"\n",
    "        xr_da.name = \"accumulation_area\"\n",
    "\n",
    "        xr_da.x.attrs[\"units\"] = \"meters\"\n",
    "        xr_da.y.attrs[\"units\"] = \"meters\"\n",
    "        xr_da.x.attrs[\"long_name\"] = 'x'\n",
    "        xr_da.y.attrs[\"long_name\"] = 'y'\n",
    "\n",
    "        return xr_da\n",
    "    \n",
    "    # for each year, open the annual AA product, reformat, save\n",
    "    for y in [2018,2019,2020,2021,2022]:\n",
    "        \n",
    "        # define paths\n",
    "        aa_path = os.path.join(folder_save, 'Annual AAs', f\"S2_{rgiid}_{y}_AA.tif\")\n",
    "        out_path = os.path.join(folder_save, 'Annual AAs', f\"S2_{rgiid}_{y}_AA_final.tif\")\n",
    "        \n",
    "        if os.path.exists(aa_path):\n",
    "            \n",
    "            # open\n",
    "            snow = riox.open_rasterio(aa_path)\n",
    "            \n",
    "            # slice slope mask to be the same as snow\n",
    "#             slope_mask = slope_mask.sel({\"x\":snow.x, \"y\":snow.y})\n",
    "\n",
    "            # give the on-glacier, no data pixels a different value\n",
    "            snow = xr.where( (snow==0) & (glacier_mask==1), 3, snow  )\n",
    "\n",
    "            # give on-glacier, steep terrain pixels the same nodata value\n",
    "            snow = xr.where( (slope_mask==0) & (glacier_mask==1), 3, snow )\n",
    "\n",
    "            # last formatting\n",
    "            snow = format_xr_to_save(snow)\n",
    "            encoding = {\"accumulation_area\":{\"zlib\": True}}\n",
    "            \n",
    "            # save\n",
    "            snow.transpose('band', 'y', 'x').rio.to_raster(raster_path=out_path, encoding=encoding)\n",
    "            \n",
    "            # remove old\n",
    "            snow.close()\n",
    "    \n",
    "    # lastly, do the same to the 5-year average product\n",
    "    # open\n",
    "    aa_path = os.path.join(folder_save, 'Average AAs', f\"S2_{rgiid}_2018_2022_average_AA.tif\")\n",
    "    out_path = os.path.join(folder_save, 'Average AAs', f\"S2_{rgiid}_2018_2022_average_AA_final.tif\")\n",
    "\n",
    "    if os.path.exists(aa_path):\n",
    "        snow = riox.open_rasterio(aa_path)\n",
    "\n",
    "        # give the on-glacier, no data pixels a different value\n",
    "        snow = xr.where( (snow==0) & (glacier_mask==1), 3, snow  )\n",
    "\n",
    "        # give on-glacier, steep terrain pixels the same nodata value\n",
    "        snow = xr.where( (slope_mask==0) & (glacier_mask==1), 3, snow )\n",
    "\n",
    "        # last formatting\n",
    "        snow = format_xr_to_save(snow)\n",
    "        encoding = {\"accumulation_area\":{\"zlib\": True}}\n",
    "\n",
    "        # save\n",
    "        snow.transpose('band', 'y', 'x').rio.to_raster(raster_path=out_path, encoding=encoding)\n",
    "        \n",
    "        # remove old\n",
    "        snow.close()\n",
    "        del snow\n",
    "  \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad4de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then go back and delete old files\n",
    "for i in range(len(rgis_to_analyze)):\n",
    "    \n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]       \n",
    "    rgiid = rgis_to_analyze[i]\n",
    "    \n",
    "    for y in [2018,2019,2020,2021,2022]:\n",
    "\n",
    "        # define paths\n",
    "        aa_path =  os.path.join(folder_save, 'Annual AAs', f\"S2_{rgiid}_{y}_AA.tif\")\n",
    "        out_path = os.path.join(folder_save, 'Annual AAs', f\"S2_{rgiid}_{y}_AA_final.tif\")\n",
    "        \n",
    "        # if everything looks good, delete\n",
    "        if os.path.exists(aa_path):\n",
    "            if os.path.exists(out_path):\n",
    "                os.remove(aa_path)\n",
    "\n",
    "    \n",
    "    # repeat for the average products\n",
    "    aa_path =  os.path.join(folder_save, 'Average AAs', f\"S2_{rgiid}_2018_2022_average_AA.tif\")\n",
    "    out_path = os.path.join(folder_save, 'Average AAs', f\"S2_{rgiid}_2018_2022_average_AA_final.tif\")\n",
    "    if os.path.exists(aa_path):\n",
    "        if os.path.exists(out_path):\n",
    "            os.remove(aa_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af042397",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
