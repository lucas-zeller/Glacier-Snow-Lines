{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dask.array\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import snowFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_dems = os.path.join(folder_AGVA, \"DEMs\", \"time_varying_DEMs\", \"10m\")\n",
    "folder_class = os.path.join(folder_AGVA, 'classified images', 'S2_Classified_Cloudmasked_Merged')\n",
    "folder_cloud = os.path.join(folder_AGVA, 'classified images', 'S2_Cloud_Merged')\n",
    "folder_meta = os.path.join(folder_AGVA, \"classified images\", \"meta csv\", \"S2\")\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"01_rgi60_Alaska\", \"01_rgi60_Alaska.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0c2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n",
      "               RGIId     Area\n",
      "548   RGI60-01.11632    [2.0]\n",
      "2815  RGI60-01.20889    [2.0]\n",
      "748   RGI60-01.25183  [2.002]\n",
      "1388  RGI60-01.08203  [2.002]\n",
      "473   RGI60-01.11595  [2.003]\n",
      "1795  RGI60-01.09047  [2.004]\n",
      "2069  RGI60-01.03614  [2.004]\n",
      "2446  RGI60-01.05487  [2.004]\n",
      "2212  RGI60-01.17509  [2.005]\n",
      "2508  RGI60-01.10867  [2.005]\n"
     ]
    }
   ],
   "source": [
    "### choose if you want to do only the 45 validation glaciers\n",
    "validation_only = 0\n",
    "\n",
    "# load rgi names that have been saved to the classified folder\n",
    "rgis_folder = list(set( [ i[3:17] for i in os.listdir(folder_class) if i!='merged.vrt' ] ))\n",
    "\n",
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "\n",
    "# get rgi names for given o2 region\n",
    "rgis_o2 = rgi_gdf[rgi_gdf['O2Region']=='4']['RGIId'].values\n",
    "\n",
    "# select which rgis to analyze\n",
    "if validation_only:\n",
    "    rgis_to_analyze = list( set(rgis_folder).intersection(set(all_validation_df['RGIId'].values)) )\n",
    "else:\n",
    "    # rgis_to_analyze = [\"RGI60-01.09162\"] # just a single rgi\n",
    "    rgis_to_analyze = rgis_folder # everything that is available\n",
    "#     rgis_to_analyze = list( set(rgis_folder).intersection(set(rgis_o2)) ) # all the rgis in the folder than are in this o2region\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "# print(rgis_to_analyze[:10])\n",
    "print(rgis_to_analyze_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d78c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 3030 of 3031: RGI60-01.13635  3025.115 km2\n"
     ]
    }
   ],
   "source": [
    "skip = 0\n",
    "for i in range(len(rgis_to_analyze)):\n",
    "    \n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]\n",
    "\n",
    "    # quickly grab glacier area\n",
    "    ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area']\n",
    "    \n",
    "    # define path that this is going to be saved to\n",
    "    path_save = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks', f\"S2_{rgiid}_mask.nc\")\n",
    "    \n",
    "    # skip if it already exists\n",
    "    if os.path.exists(path_save):\n",
    "        continue\n",
    "    \n",
    "    # print progress\n",
    "    print(f\"Starting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga.values[0]} km2\")\n",
    "    \n",
    "    # grab just this rgi geometry and info\n",
    "    rgi_single = rgi_gdf[rgi_gdf['RGIId']==rgiid].to_crs(\"EPSG:3338\")\n",
    "    single_geometry = rgi_single.geometry\n",
    "\n",
    "    # open the classification data\n",
    "    file_name = f\"S2_{rgiid}_2018-01-01_2023-01-01\"\n",
    "    xr_class = riox.open_rasterio(os.path.join(folder_class, f\"{file_name}.tif\")).chunk({'band':-1, 'y':1000, 'x':1000})#.rio.clip(single_geometry, from_disk=True, drop=True).chunk()\n",
    "\n",
    "    # load metadata csv, convert date to datetimes\n",
    "    meta_fp = os.path.join(folder_meta, f\"{file_name}.csv\")\n",
    "    meta_df = pd.read_csv(meta_fp)\n",
    "    \n",
    "    # format time axis to pandas datetime, like xarray wants\n",
    "    datetimes = pd.to_datetime([f\"{str(i)[:4]}-{str(i)[4:6]}-{str(i)[6:]}\" for i in meta_df['date']])\n",
    "    xr_class = xr_class.rename({\"band\":\"time\"})\n",
    "    xr_class['time'] = datetimes\n",
    "\n",
    "    # merge images on same day, if there are repeated dates\n",
    "#     if len(datetimes)!=len(datetimes.unique()):\n",
    "#         xr_class = xr_class.where(xr_class<20, 0).groupby('time').max('time')\n",
    "#     else:\n",
    "#         xr_class = xr_class.where(xr_class<20, 0)\n",
    "       \n",
    "    # calculate maximum through time\n",
    "    glacier_mask = xr_class.max(dim='time').rename('class')\n",
    "    glacier_mask = (glacier_mask>0)#.astype(int)\n",
    "    \n",
    "    def format_xr_to_save(xr_da):\n",
    "            xr_da.attrs[\"res\"] = (10,10)\n",
    "            xr_da.attrs[\"crs\"] = \"EPSG:3338\"\n",
    "            xr_da.attrs[\"transform\"] = [10,0,0,0,-10,0]\n",
    "#             xr_da.attrs[\"_FillValue\"] = 0\n",
    "            xr_da.attrs[\"long_name\"] = rgiid\n",
    "            xr_da.attrs[\"description\"] = \"0: off 1: on\"\n",
    "            xr_da.name = \"glacier\"\n",
    "\n",
    "            xr_da.x.attrs[\"units\"] = \"meters\"\n",
    "            xr_da.y.attrs[\"units\"] = \"meters\"\n",
    "            xr_da.x.attrs[\"long_name\"] = 'x'\n",
    "            xr_da.y.attrs[\"long_name\"] = 'y'\n",
    "\n",
    "            return xr_da\n",
    "        \n",
    "    # format everything correctly    \n",
    "    glacier_mask = format_xr_to_save(glacier_mask)\n",
    "    \n",
    "    # specify compression/encoding\n",
    "    encoding = {\"glacier\":{\"zlib\": True}}#, \"spatial_ref\":{\"zlib\": False}}\n",
    "\n",
    "    # save\n",
    "    glacier_mask.to_netcdf(path_save, encoding=encoding)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
