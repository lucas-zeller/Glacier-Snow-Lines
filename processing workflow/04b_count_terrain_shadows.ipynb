{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d726caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import dask.array\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import snowFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_dems = os.path.join(folder_AGVA, \"DEMs\", \"time_varying_DEMs\", \"10m\")\n",
    "folder_class = os.path.join(folder_AGVA, 'classified images', 'S2_Classified_Cloudmasked_Merged')\n",
    "folder_cloud = os.path.join(folder_AGVA, 'classified images', 'S2_Cloud_Merged')\n",
    "folder_meta = os.path.join(folder_AGVA, \"classified images\", \"meta csv\", \"S2\")\n",
    "folder_mask = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks')\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"rgi_2km_o3regions\", \"rgi_2km_o3regions.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0c2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "### choose if you want to do only the 45 validation glaciers\n",
    "validation_only = 1\n",
    "\n",
    "# load rgi names that have been saved to the classified folder\n",
    "rgis_folder = list(set( [ i[3:17] for i in os.listdir(folder_class) if i!='merged.vrt' ] ))\n",
    "\n",
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "\n",
    "# get rgi names for given o2 region\n",
    "rgis_o2 = rgi_gdf[rgi_gdf['O2Region']=='4']['RGIId'].values\n",
    "\n",
    "# select which rgis to analyze\n",
    "if validation_only:\n",
    "    rgis_to_analyze = list( set(rgis_folder).intersection(set(all_validation_df['RGIId'].values)) )\n",
    "else:\n",
    "    # rgis_to_analyze = [\"RGI60-01.09162\"] # just a single rgi\n",
    "    rgis_to_analyze = rgis_folder # everything that is available\n",
    "#     rgis_to_analyze = list( set(rgis_folder).intersection(set(rgis_o2)) ) # all the rgis in the folder than are in this o2region\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "# print(rgis_to_analyze[:10])\n",
    "# print(rgis_to_analyze_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d78c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 1 of 45: RGI60-01.10910  2.084 km2\n",
      "\n",
      "Starting 2 of 45: RGI60-01.00787  2.126 km2\n",
      "\n",
      "Starting 3 of 45: RGI60-01.23606  2.344 km2\n",
      "\n",
      "Starting 4 of 45: RGI60-01.15253  2.551 km2\n",
      "\n",
      "Starting 5 of 45: RGI60-01.03379  2.578 km2\n",
      "\n",
      "Starting 6 of 45: RGI60-01.16719  2.681 km2\n",
      "\n",
      "Starting 7 of 45: RGI60-01.17321  2.88 km2\n",
      "\n",
      "Starting 8 of 45: RGI60-01.13462  3.206 km2\n",
      "\n",
      "Starting 9 of 45: RGI60-01.13483  3.216 km2\n",
      "\n",
      "Starting 10 of 45: RGI60-01.02584  3.441 km2\n",
      "\n",
      "Starting 11 of 45: RGI60-01.03215  3.998 km2\n",
      "\n",
      "Starting 12 of 45: RGI60-01.01666  4.243 km2\n",
      "\n",
      "Starting 13 of 45: RGI60-01.12548  4.314 km2\n",
      "\n",
      "Starting 14 of 45: RGI60-01.13930  4.404 km2\n",
      "\n",
      "Starting 15 of 45: RGI60-01.09624  4.487 km2\n",
      "\n",
      "Starting 16 of 45: RGI60-01.15516  4.764 km2\n",
      "\n",
      "Starting 17 of 45: RGI60-01.21721  6.422 km2\n",
      "\n",
      "Starting 18 of 45: RGI60-01.10255  7.262 km2\n",
      "\n",
      "Starting 19 of 45: RGI60-01.12165  7.969 km2\n",
      "\n",
      "Starting 20 of 45: RGI60-01.05007  9.216 km2\n",
      "\n",
      "Starting 21 of 45: RGI60-01.01104  9.528 km2\n",
      "\n",
      "Starting 22 of 45: RGI60-01.12186  11.05 km2\n",
      "\n",
      "Starting 23 of 45: RGI60-01.09656  13.791 km2\n",
      "\n",
      "Starting 24 of 45: RGI60-01.17784  14.773 km2\n",
      "\n",
      "Starting 25 of 45: RGI60-01.14493  15.336 km2\n",
      "\n",
      "Starting 26 of 45: RGI60-01.23643  15.732 km2\n",
      "\n",
      "Starting 27 of 45: RGI60-01.01270  16.163 km2\n",
      "\n",
      "Starting 28 of 45: RGI60-01.09162  16.749 km2\n",
      "\n",
      "Starting 29 of 45: RGI60-01.05078  17.259 km2\n",
      "\n",
      "Starting 30 of 45: RGI60-01.00570  17.567 km2\n",
      "\n",
      "Starting 31 of 45: RGI60-01.00557  18.042 km2\n",
      "\n",
      "Starting 32 of 45: RGI60-01.09216  18.634 km2\n",
      "\n",
      "Starting 33 of 45: RGI60-01.26731  20.207 km2\n",
      "\n",
      "Starting 34 of 45: RGI60-01.00565  23.06 km2\n",
      "\n",
      "Starting 35 of 45: RGI60-01.08989  29.395 km2\n",
      "\n",
      "Starting 36 of 45: RGI60-01.16166  29.932 km2\n",
      "\n",
      "Starting 37 of 45: RGI60-01.15731  40.009 km2\n",
      "\n",
      "Starting 38 of 45: RGI60-01.09798  41.785 km2\n",
      "\n",
      "Starting 39 of 45: RGI60-01.01743  45.165 km2\n",
      "\n",
      "Starting 40 of 45: RGI60-01.15135  66.067 km2\n",
      "\n",
      "Starting 41 of 45: RGI60-01.19542  71.722 km2\n",
      "\n",
      "Starting 42 of 45: RGI60-01.20841  80.284 km2\n",
      "\n",
      "Starting 43 of 45: RGI60-01.03741  136.264 km2\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "\n",
      "Starting 44 of 45: RGI60-01.16558  343.098 km2\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "\n",
      "Starting 45 of 45: RGI60-01.01390  521.396 km2\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(rgis_to_analyze)):\n",
    "#     if c>0: continue\n",
    "    \n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]\n",
    "\n",
    "    # quickly grab glacier area\n",
    "    ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area'].values[0]\n",
    "\n",
    "#     if ga<500: continue\n",
    "        \n",
    "    # choose how much to coarsen (more coarse for bigger glaciers) \n",
    "    if ga>1000:\n",
    "        scale=5\n",
    "    elif ga>500:\n",
    "        scale=3\n",
    "    else:\n",
    "        scale=1\n",
    "    \n",
    "    # set folder\n",
    "    if validation_only:\n",
    "        folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Validation')\n",
    "    else:\n",
    "        folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2')\n",
    "       \n",
    "    # print progress\n",
    "    print(f\"\\nStarting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga} km2\")\n",
    "    \n",
    "    # grab just this rgi geometry and info\n",
    "    rgi_single = rgi_gdf[rgi_gdf['RGIId']==rgiid].to_crs(\"EPSG:3338\")\n",
    "    single_geometry = rgi_single.geometry\n",
    "\n",
    "    # open glacier mask\n",
    "    glacier_mask = xr.open_dataset(os.path.join(folder_mask, f\"S2_{rgiid}_mask.nc\"), chunks='auto').glacier\n",
    "    \n",
    "    # coarsen if this is a big glacier\n",
    "#     if ga>500:\n",
    "#         glacier_mask = glacier_mask.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True).astype('uint8')\n",
    "    \n",
    "    # count pixels\n",
    "    glacier_pixels = glacier_mask.sum().values\n",
    "\n",
    "    # open obs_df\n",
    "    obs_path = os.path.join(folder_save, 'Daily AAs', 'observed', f\"S2_{rgiid}_observed.csv\")\n",
    "    obs_df = pd.read_csv(obs_path)\n",
    "    \n",
    "    # for each year, open the daily shadow data, count usable, save to df\n",
    "    for y in [2018,2019,2020,2021,2022]:\n",
    "        if ga>100: print(y)\n",
    "        \n",
    "        # define path to shadow data\n",
    "        path_shadow = os.path.join(folder_save, 'Shadows', f\"S2_{rgiid}_{y}_daily_shadows.nc\")\n",
    "        \n",
    "        # open, changing the chunk size depending on glacier area\n",
    "        if ga>1000:\n",
    "            chunks={'time':1}\n",
    "        elif ga>100:\n",
    "            chunks={'time':10}\n",
    "        else:\n",
    "            chunks='auto'\n",
    "            \n",
    "        shadows = xr.open_dataset(path_shadow, chunks=chunks).to_array()\n",
    "        \n",
    "        # get dates\n",
    "        dates = shadows.time.values\n",
    "        dates = [str(d)[:10] for d in dates]\n",
    "        \n",
    "        # count usable fraction each date\n",
    "        percent_usable_by_time = shadows.sum(dim=['x','y']).values[0] #.compute().values[0][0]\n",
    "        \n",
    "        # scale correctly\n",
    "        percent_usable_by_time = percent_usable_by_time/glacier_pixels #*scale*scale\n",
    "        \n",
    "        # put these in the df       \n",
    "        obs_df.loc[obs_df['Date'].isin(dates), 'terrain_shadows'] = (1-percent_usable_by_time).round(4)\n",
    "\n",
    "    # format df and save\n",
    "    obs_df.to_csv(obs_path, index=False)\n",
    "    c+=1\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318adc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>observed_initial</th>\n",
       "      <th>terrain_shadows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-12</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  observed_initial  terrain_shadows\n",
       "0  2018-05-02            0.0427           0.0008\n",
       "1  2018-05-04            0.0000           0.0007\n",
       "2  2018-05-07            0.8243           0.0006\n",
       "3  2018-05-09            0.9152           0.0006\n",
       "4  2018-05-12            0.2016           0.0005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de973088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
