{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed27064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dask.array\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import snowFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d945ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder and file paths\n",
    "folder_AGVA = os.path.join('C:',os.sep,'Users','lzell','OneDrive - Colostate','Desktop',\"AGVA\")\n",
    "folder_dems = os.path.join(folder_AGVA, \"DEMs\", \"time_varying_DEMs\", \"10m\")\n",
    "folder_class = os.path.join(folder_AGVA, 'classified images', 'S2_Classified_Cloudmasked_Merged')\n",
    "folder_cloud = os.path.join(folder_AGVA, 'classified images', 'S2_Cloud_Merged')\n",
    "folder_meta = os.path.join(folder_AGVA, \"classified images\", \"meta csv\", \"S2\")\n",
    "folder_mask = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Masks')\n",
    "\n",
    "# open rgi\n",
    "path_rgi = os.path.join(folder_AGVA, 'RGI', \"rgi_2km_o3regions\", \"rgi_2km_o3regions.shp\")\n",
    "rgi_gdf = gpd.read_file(path_rgi, drop='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f735687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "### choose if you want to do only the 45 validation glaciers\n",
    "validation_only = 1\n",
    "\n",
    "# open list of validation glaciers\n",
    "all_validation_df = pd.read_csv(os.path.join(folder_AGVA, 'Validation', 'Validation Glaciers.csv'))\n",
    "\n",
    "# select which rgis to analyze\n",
    "if validation_only:\n",
    "    folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2', 'Validation')\n",
    "else:\n",
    "    folder_save = os.path.join(folder_AGVA, 'Derived products', 'S2')\n",
    "\n",
    "# get list of rgis to analyze\n",
    "rgis_to_analyze = list(set( [ i[3:17] for i in os.listdir(os.path.join(folder_save, \"Average AAs\")) if i[-3:]=='tif' ] ))\n",
    "\n",
    "# get list of glacier area for each rgi\n",
    "areas = [rgi_gdf[rgi_gdf['RGIId']==i]['Area'].values for i in rgis_to_analyze]\n",
    "\n",
    "# make df\n",
    "rgis_to_analyze_df = pd.DataFrame({\"RGIId\":rgis_to_analyze, 'Area':areas})\n",
    "\n",
    "# sort however you want\n",
    "rgis_to_analyze_df = rgis_to_analyze_df.sort_values('Area')\n",
    "\n",
    "# grab rgi names\n",
    "rgis_to_analyze = rgis_to_analyze_df['RGIId'].values\n",
    "\n",
    "print(len(rgis_to_analyze_df))\n",
    "# print(rgis_to_analyze[:10])\n",
    "# print(rgis_to_analyze_df[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd66203",
   "metadata": {},
   "source": [
    "### First step: go through to get the snow cover fraction of elevation bands in the average AA product for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 of 45: RGI60-01.10910  2.084 km2\n",
      "Starting 2 of 45: RGI60-01.00787  2.126 km2\n",
      "Starting 3 of 45: RGI60-01.23606  2.344 km2\n",
      "Starting 4 of 45: RGI60-01.15253  2.551 km2\n",
      "Starting 5 of 45: RGI60-01.03379  2.578 km2\n",
      "Starting 6 of 45: RGI60-01.16719  2.681 km2\n",
      "Starting 7 of 45: RGI60-01.17321  2.88 km2\n",
      "Starting 8 of 45: RGI60-01.13462  3.206 km2\n",
      "Starting 9 of 45: RGI60-01.13483  3.216 km2\n",
      "Starting 10 of 45: RGI60-01.02584  3.441 km2\n",
      "Starting 11 of 45: RGI60-01.03215  3.998 km2\n",
      "Starting 12 of 45: RGI60-01.01666  4.243 km2\n",
      "Starting 13 of 45: RGI60-01.12548  4.314 km2\n",
      "Starting 14 of 45: RGI60-01.13930  4.404 km2\n",
      "Starting 15 of 45: RGI60-01.09624  4.487 km2\n",
      "Starting 16 of 45: RGI60-01.15516  4.764 km2\n",
      "Starting 17 of 45: RGI60-01.21721  6.422 km2\n",
      "Starting 18 of 45: RGI60-01.10255  7.262 km2\n",
      "Starting 19 of 45: RGI60-01.12165  7.969 km2\n",
      "Starting 20 of 45: RGI60-01.05007  9.216 km2\n",
      "Starting 21 of 45: RGI60-01.01104  9.528 km2\n",
      "Starting 22 of 45: RGI60-01.12186  11.05 km2\n",
      "Starting 23 of 45: RGI60-01.09656  13.791 km2\n",
      "Starting 24 of 45: RGI60-01.17784  14.773 km2\n",
      "Starting 25 of 45: RGI60-01.14493  15.336 km2\n",
      "Starting 26 of 45: RGI60-01.23643  15.732 km2\n",
      "Starting 27 of 45: RGI60-01.01270  16.163 km2\n",
      "Starting 28 of 45: RGI60-01.09162  16.749 km2\n",
      "Starting 29 of 45: RGI60-01.05078  17.259 km2\n",
      "Starting 30 of 45: RGI60-01.00570  17.567 km2\n",
      "Starting 31 of 45: RGI60-01.00557  18.042 km2\n",
      "Starting 32 of 45: RGI60-01.09216  18.634 km2\n",
      "Starting 33 of 45: RGI60-01.26731  20.207 km2\n",
      "Starting 34 of 45: RGI60-01.00565  23.06 km2\n",
      "Starting 35 of 45: RGI60-01.08989  29.395 km2\n",
      "Starting 36 of 45: RGI60-01.16166  29.932 km2\n",
      "Starting 37 of 45: RGI60-01.15731  40.009 km2\n",
      "Starting 38 of 45: RGI60-01.09798  41.785 km2\n",
      "Starting 39 of 45: RGI60-01.01743  45.165 km2\n",
      "Starting 40 of 45: RGI60-01.15135  66.067 km2\n",
      "Starting 41 of 45: RGI60-01.19542  71.722 km2\n",
      "Starting 42 of 45: RGI60-01.20841  80.284 km2\n",
      "Starting 43 of 45: RGI60-01.03741  136.264 km2\n",
      "Starting 44 of 45: RGI60-01.16558  343.098 km2\n",
      "Starting 45 of 45: RGI60-01.01390  521.396 km2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rgis_to_analyze)):\n",
    "\n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]\n",
    "\n",
    "    # check if we've already run this glacier. if so, skip\n",
    "    temp_path = os.path.join(folder_save, 'Average AAs', 'Band SCFs', f\"{rgiid}.csv\")\n",
    "    if os.path.exists(temp_path):\n",
    "        continue\n",
    "\n",
    "    # quickly grab glacier area\n",
    "    ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area'].values[0]\n",
    "\n",
    "    # print progress\n",
    "    print(f\"Starting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga} km2\")\n",
    "    \n",
    "    # grab just this rgi geometry and info\n",
    "    rgi_single = rgi_gdf[rgi_gdf['RGIId']==rgiid].to_crs(\"EPSG:3338\")\n",
    "    single_geometry = rgi_single.geometry\n",
    "    \n",
    "    # define the coarsen scale\n",
    "    if ga>1000:\n",
    "        scale=5\n",
    "    elif ga>500:\n",
    "        scale=3\n",
    "        \n",
    "    # open glacier mask\n",
    "    glacier_mask = xr.open_dataset(os.path.join(folder_mask, f\"S2_{rgiid}_mask.nc\"), chunks='auto').glacier\n",
    "    \n",
    "    if ga>500:\n",
    "        glacier_mask = glacier_mask.coarsen({\"x\":scale, \"y\":scale}, boundary=\"trim\").median(skipna=True).astype('uint8')  \n",
    "    \n",
    "    # open the average AA map\n",
    "    path_open = os.path.join(folder_save, 'Average AAs', f\"S2_{rgiid}_2018_2022_average_AA_final.tif\")\n",
    "    snow = riox.open_rasterio(path_open)\n",
    "#     snow = xr.open_dataset(path_open)[\"accumulation_area\"]#.rename({'band':'time'})\n",
    "    \n",
    "    # if 3d, rename \"band\" to \"time\". otherwise if 2d add a time dimension\n",
    "    if len(snow.shape)==3:\n",
    "        snow = snow.rename({'band':'time'})\n",
    "    else:\n",
    "        snow = snow.expand_dims(dim='time', axis=0)\n",
    "        snow['time'] = [1]\n",
    "    \n",
    "    # make to nan, 0, 1 (instead of 0,1,2,3) (0 and 3 to np.nan, 1 to 0, 2 to 1)\n",
    "    snow = xr.where(snow.isin([0,3]), np.nan, snow-1)\n",
    "    \n",
    "    # open dem for year 2020\n",
    "    xr_dem = snowFun.get_year_DEM(single_geometry, 2020, smoothed=0) \n",
    "    \n",
    "    # coarsen dem\n",
    "    if ga>500:\n",
    "        xr_dem = xr_dem.sel({\"x\":snow.x, \"y\":snow.y})\n",
    "\n",
    "    # shave off edges to make sure dem, mask match\n",
    "    xr_dem = xr_dem.sel(x=slice( min(glacier_mask.x.values), max(glacier_mask.x.values) ), y=slice(max(glacier_mask.y.values),min(glacier_mask.y.values)))\n",
    "    glacier_mask = glacier_mask.sel(x=slice( min(xr_dem.x.values), max(xr_dem.x.values) ), y=slice(max(xr_dem.y.values),min(xr_dem.y.values)))\n",
    "    snow = snow.sel(x=slice( min(xr_dem.x.values), max(xr_dem.x.values) ), y=slice(max(xr_dem.y.values),min(xr_dem.y.values)))\n",
    "    \n",
    "    # extract number of snow pixels in bands from each time step\n",
    "    snow_df = snowFun.extract_band_SCA(snow, xr_dem, glacier_mask, step=10)\n",
    "    snow_df = snow_df.rename(columns={'total_pixels':f\"total_pixels_possible\", '1':'snow'})\n",
    "\n",
    "    # extract number of pixels observed in bands from each time step\n",
    "    obs_df = snowFun.extract_band_SCA( xr.where(snow>=0, 1, 0) , xr_dem, glacier_mask, step=10)\n",
    "    obs_df = obs_df.rename(columns={'total_pixels':f\"total_pixels_possible\", '1':'observed'})\n",
    "\n",
    "    # add snow_df to obs_df\n",
    "    obs_df['snow'] = snow_df['snow']\n",
    "    \n",
    "    # save to csv\n",
    "    out_path = os.path.join(folder_save, 'Average AAs', 'Band SCFs', f\"{rgiid}.csv\")\n",
    "    obs_df.to_csv(out_path, index=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d883ee",
   "metadata": {},
   "source": [
    "### Second step: go through those snow cover fraction products to calculate the ELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2286712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 of 45: RGI60-01.10910  2.084 km2\n",
      "Starting 2 of 45: RGI60-01.00787  2.126 km2\n",
      "Starting 3 of 45: RGI60-01.23606  2.344 km2\n",
      "Starting 4 of 45: RGI60-01.15253  2.551 km2\n",
      "Starting 5 of 45: RGI60-01.03379  2.578 km2\n",
      "Starting 6 of 45: RGI60-01.16719  2.681 km2\n",
      "Starting 7 of 45: RGI60-01.17321  2.88 km2\n",
      "Starting 8 of 45: RGI60-01.13462  3.206 km2\n",
      "Starting 9 of 45: RGI60-01.13483  3.216 km2\n",
      "Starting 10 of 45: RGI60-01.02584  3.441 km2\n",
      "Starting 11 of 45: RGI60-01.03215  3.998 km2\n",
      "Starting 12 of 45: RGI60-01.01666  4.243 km2\n",
      "Starting 13 of 45: RGI60-01.12548  4.314 km2\n",
      "Starting 14 of 45: RGI60-01.13930  4.404 km2\n",
      "Starting 15 of 45: RGI60-01.09624  4.487 km2\n",
      "Starting 16 of 45: RGI60-01.15516  4.764 km2\n",
      "Starting 17 of 45: RGI60-01.21721  6.422 km2\n",
      "Starting 18 of 45: RGI60-01.10255  7.262 km2\n",
      "Starting 19 of 45: RGI60-01.12165  7.969 km2\n",
      "Starting 20 of 45: RGI60-01.05007  9.216 km2\n",
      "Starting 21 of 45: RGI60-01.01104  9.528 km2\n",
      "Starting 22 of 45: RGI60-01.12186  11.05 km2\n",
      "Starting 23 of 45: RGI60-01.09656  13.791 km2\n",
      "Starting 24 of 45: RGI60-01.17784  14.773 km2\n",
      "Starting 25 of 45: RGI60-01.14493  15.336 km2\n",
      "Starting 26 of 45: RGI60-01.23643  15.732 km2\n",
      "Starting 27 of 45: RGI60-01.01270  16.163 km2\n",
      "Starting 28 of 45: RGI60-01.09162  16.749 km2\n",
      "Starting 29 of 45: RGI60-01.05078  17.259 km2\n",
      "Starting 30 of 45: RGI60-01.00570  17.567 km2\n",
      "Starting 31 of 45: RGI60-01.00557  18.042 km2\n",
      "Starting 32 of 45: RGI60-01.09216  18.634 km2\n",
      "Starting 33 of 45: RGI60-01.26731  20.207 km2\n",
      "Starting 34 of 45: RGI60-01.00565  23.06 km2\n",
      "Starting 35 of 45: RGI60-01.08989  29.395 km2\n",
      "Starting 36 of 45: RGI60-01.16166  29.932 km2\n",
      "Starting 37 of 45: RGI60-01.15731  40.009 km2\n",
      "Starting 38 of 45: RGI60-01.09798  41.785 km2\n",
      "Starting 39 of 45: RGI60-01.01743  45.165 km2\n",
      "Starting 40 of 45: RGI60-01.15135  66.067 km2\n",
      "Starting 41 of 45: RGI60-01.19542  71.722 km2\n",
      "Starting 42 of 45: RGI60-01.20841  80.284 km2\n",
      "Starting 43 of 45: RGI60-01.03741  136.264 km2\n",
      "Starting 44 of 45: RGI60-01.16558  343.098 km2\n",
      "Starting 45 of 45: RGI60-01.01390  521.396 km2\n"
     ]
    }
   ],
   "source": [
    "all_obs = []\n",
    "for i in range(len(rgis_to_analyze)):\n",
    "#     if i>0: continue\n",
    "    # subset rgi to single outline, by choosing rgiid or rgi name\n",
    "    rgiid = rgis_to_analyze[i]\n",
    "\n",
    "    # quickly grab glacier area\n",
    "    ga = rgi_gdf[rgi_gdf['RGIId']==rgiid]['Area'].values[0]\n",
    "    \n",
    "    # define scale\n",
    "    if ga>1000:\n",
    "        scale=5\n",
    "    elif ga>500:\n",
    "        scale=3\n",
    "    else:\n",
    "        scale=1\n",
    "\n",
    "    # print progress\n",
    "    print(f\"Starting {i+1} of {len(rgis_to_analyze)}: {rgiid}  {ga} km2\")\n",
    "    \n",
    "    # open the csv hold elevation-band scfs\n",
    "    open_path = os.path.join(folder_save, 'Average AAs', 'Band SCFs', f\"{rgiid}.csv\")\n",
    "    scf_df = pd.read_csv(open_path)\n",
    "    \n",
    "    # calculate fraction of each band that was observed and that was snow (relative to observed)\n",
    "    scf_df['observed_frac'] = scf_df['observed']/scf_df['total_pixels_possible'].fillna(0)\n",
    "    scf_df['total_snow_frac'] = scf_df['snow']/scf_df['total_pixels_possible'].fillna(0)\n",
    "    scf_df['snow_frac'] = scf_df['snow']/scf_df['observed'].fillna(0)\n",
    "    \n",
    "    ## we need to remove elevation bands that have essentially no observations.\n",
    "    good_bands = (scf_df['observed']>50)\n",
    "    \n",
    "    df_to_use = scf_df[good_bands].reset_index()\n",
    "#     df_observed = df_observed[good_bands].reset_index()\n",
    "    \n",
    "    # transition to numpy array for a bit. snow fractions >=0.5 become 1 (accumulation zone)\n",
    "    # everything <0.5 becomes 0 (ablation)\n",
    "    np_accumulation = df_to_use['snow_frac'].values\n",
    "    np_accumulation[np_accumulation>=0.5] = 1\n",
    "    np_accumulation[np_accumulation<0.5] = 0\n",
    "    \n",
    "    # Define a kernel that sums the next 5 (4,3,2,1...) values along the 2nd dimension\n",
    "    kernel5 = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "    kernel4 = np.array([1, 1, 1, 1, 0, 0, 0])\n",
    "    kernel3 = np.array([1, 1, 1, 0, 0])\n",
    "    \n",
    "    # apply kernel 5, see if we have an elevation band that is start of 5 accumulation bands in a row\n",
    "    all_elas_5 = np.convolve(np_accumulation, kernel5, mode='same')==5\n",
    "    all_elas_4 = np.convolve(np_accumulation, kernel4, mode='same')==4\n",
    "    all_elas_3 = np.convolve(np_accumulation, kernel3, mode='same')==3\n",
    "    \n",
    "    first_ela_5 = np.argmax(all_elas_5, axis=0).astype(float)\n",
    "    first_ela_4 = np.argmax(all_elas_4, axis=0).astype(float)\n",
    "    first_ela_3 = np.argmax(all_elas_3, axis=0).astype(float)\n",
    "    \n",
    "    # if all 0s, replace with nan\n",
    "    if all_elas_5.sum()==0: first_ela_5 = np.nan\n",
    "    if all_elas_4.sum()==0: first_ela_4 = np.nan\n",
    "    if all_elas_3.sum()==0: first_ela_3 = np.nan\n",
    "\n",
    "    # get the final ela, by first taking from 5, then 4, then 3\n",
    "    final_ela = first_ela_5\n",
    "    if np.isnan(final_ela): final_ela = first_ela_4\n",
    "    if np.isnan(final_ela): final_ela = first_ela_3\n",
    "        \n",
    "    # lastly, if we still have no ela (the entire glacier is ablation) we'll put the highest elevation band as the ela\n",
    "    # make a separate flag for these\n",
    "    off_glacier_flag = int(np.isnan(final_ela))\n",
    "    \n",
    "    # translate final_ela to elevation\n",
    "    if np.isnan(final_ela):\n",
    "        final_ela = df_to_use['z_min'].values[-1]\n",
    "    else:\n",
    "        final_ela = df_to_use['z_min'][final_ela]\n",
    "    \n",
    "    # calculate fraction observed, aar\n",
    "    final_observed_frac = round(np.nansum(scf_df['observed'])/np.nansum(scf_df['total_pixels_possible']),4)\n",
    "    final_aar = round(np.nansum(scf_df['snow'])/np.nansum(scf_df['observed']),4)\n",
    "    total_area = np.nansum(scf_df['total_pixels_possible'])*scale*scale*10*10 / (1000*1000) #km2\n",
    "    total_observed = np.nansum(scf_df['observed'])*scale*scale*10*10 / (1000*1000) #km2\n",
    "    total_snow = np.nansum(scf_df['snow'])*scale*scale*10*10 / (1000*1000) #km2\n",
    "    \n",
    "    # format all the data for this glacier to save\n",
    "    final_obs = {\"RGIId\":rgiid,\n",
    "                 \"ela\":int(final_ela),\n",
    "                 \"aar\":final_aar,\n",
    "                 \"off_glacier\":off_glacier_flag,\n",
    "                 \"total_area\":round(total_area,4),\n",
    "                 \"total_observed\":round(total_observed,4),\n",
    "                 \"total_snow\":round(total_snow,4)}\n",
    "    \n",
    "    # save to list\n",
    "    all_obs.append(final_obs)\n",
    "\n",
    "# format final df\n",
    "all_obs_df = pd.DataFrame(all_obs)\n",
    "\n",
    "# save\n",
    "out_path = os.path.join(folder_save, 'Average AAs', 'final_glacier_stats.csv')\n",
    "all_obs_df.to_csv(out_path, index=False)\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
